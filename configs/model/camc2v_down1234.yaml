base_learning_rate: 1e-5
pretrained_checkpoint: ckpts/dynamicrafter/model.ckpt

target: model.camc2v.CamC2V
params:
  diffusion_model_trainable: false
  image_proj_model_trainable: false
  diffusion_model_trainable_parameters:
    - input_blocks.0.0.bias
    - input_blocks.0.0.weight
    - input_blocks.1.0.emb_layers.1.bias
    - input_blocks.1.0.emb_layers.1.weight
    - input_blocks.1.0.in_layers.0.bias
    - input_blocks.1.0.in_layers.0.weight
    - input_blocks.1.0.in_layers.2.bias
    - input_blocks.1.0.in_layers.2.weight
    - input_blocks.1.0.out_layers.0.bias
    - input_blocks.1.0.out_layers.0.weight
    - input_blocks.1.0.out_layers.3.bias
    - input_blocks.1.0.out_layers.3.weight
    - input_blocks.1.0.temopral_conv.conv1.0.bias
    - input_blocks.1.0.temopral_conv.conv1.0.weight
    - input_blocks.1.0.temopral_conv.conv1.2.bias
    - input_blocks.1.0.temopral_conv.conv1.2.weight
    - input_blocks.1.0.temopral_conv.conv2.0.bias
    - input_blocks.1.0.temopral_conv.conv2.0.weight
    - input_blocks.1.0.temopral_conv.conv2.3.bias
    - input_blocks.1.0.temopral_conv.conv2.3.weight
    - input_blocks.1.0.temopral_conv.conv3.0.bias
    - input_blocks.1.0.temopral_conv.conv3.0.weight
    - input_blocks.1.0.temopral_conv.conv3.3.bias
    - input_blocks.1.0.temopral_conv.conv3.3.weight
    - input_blocks.1.0.temopral_conv.conv4.0.bias
    - input_blocks.1.0.temopral_conv.conv4.0.weight
    - input_blocks.1.0.temopral_conv.conv4.3.bias
    - input_blocks.1.0.temopral_conv.conv4.3.weight
    - input_blocks.1.1.norm.bias
    - input_blocks.1.1.norm.weight
    - input_blocks.1.1.proj_in.bias
    - input_blocks.1.1.proj_in.weight
    - input_blocks.1.1.proj_out.bias
    - input_blocks.1.1.proj_out.weight
    - input_blocks.1.1.transformer_blocks.0.attn1.to_k.weight
    - input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.bias
    - input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.weight
    - input_blocks.1.1.transformer_blocks.0.attn1.to_q.weight
    - input_blocks.1.1.transformer_blocks.0.attn1.to_v.weight
    - input_blocks.1.1.transformer_blocks.0.attn2.alpha
    - input_blocks.1.1.transformer_blocks.0.attn2.to_k.weight
    - input_blocks.1.1.transformer_blocks.0.attn2.to_k_ip.weight
    - input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.bias
    - input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.weight
    - input_blocks.1.1.transformer_blocks.0.attn2.to_q.weight
    - input_blocks.1.1.transformer_blocks.0.attn2.to_v.weight
    - input_blocks.1.1.transformer_blocks.0.attn2.to_v_ip.weight
    - input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.bias
    - input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.weight
    - input_blocks.1.1.transformer_blocks.0.ff.net.2.bias
    - input_blocks.1.1.transformer_blocks.0.ff.net.2.weight
    - input_blocks.1.1.transformer_blocks.0.norm1.bias
    - input_blocks.1.1.transformer_blocks.0.norm1.weight
    - input_blocks.1.1.transformer_blocks.0.norm2.bias
    - input_blocks.1.1.transformer_blocks.0.norm2.weight
    - input_blocks.1.1.transformer_blocks.0.norm3.bias
    - input_blocks.1.1.transformer_blocks.0.norm3.weight
    - input_blocks.1.2.norm.bias
    - input_blocks.1.2.norm.weight
    - input_blocks.1.2.proj_in.bias
    - input_blocks.1.2.proj_in.weight
    - input_blocks.1.2.proj_out.bias
    - input_blocks.1.2.proj_out.weight
    - input_blocks.1.2.transformer_blocks.0.attn1.to_k.weight
    - input_blocks.1.2.transformer_blocks.0.attn1.to_out.0.bias
    - input_blocks.1.2.transformer_blocks.0.attn1.to_out.0.weight
    - input_blocks.1.2.transformer_blocks.0.attn1.to_q.weight
    - input_blocks.1.2.transformer_blocks.0.attn1.to_v.weight
    - input_blocks.1.2.transformer_blocks.0.attn2.to_k.weight
    - input_blocks.1.2.transformer_blocks.0.attn2.to_out.0.bias
    - input_blocks.1.2.transformer_blocks.0.attn2.to_out.0.weight
    - input_blocks.1.2.transformer_blocks.0.attn2.to_q.weight
    - input_blocks.1.2.transformer_blocks.0.attn2.to_v.weight
    - input_blocks.1.2.transformer_blocks.0.epipolar.epipolar_attn.register_tokens
    - input_blocks.1.2.transformer_blocks.0.epipolar.epipolar_attn.to_k.weight
    - input_blocks.1.2.transformer_blocks.0.epipolar.epipolar_attn.to_out.0.bias
    - input_blocks.1.2.transformer_blocks.0.epipolar.epipolar_attn.to_out.0.weight
    - input_blocks.1.2.transformer_blocks.0.epipolar.epipolar_attn.to_q.weight
    - input_blocks.1.2.transformer_blocks.0.epipolar.epipolar_attn.to_v.weight
    - input_blocks.1.2.transformer_blocks.0.ff.net.0.proj.bias
    - input_blocks.1.2.transformer_blocks.0.ff.net.0.proj.weight
    - input_blocks.1.2.transformer_blocks.0.ff.net.2.bias
    - input_blocks.1.2.transformer_blocks.0.ff.net.2.weight
    - input_blocks.1.2.transformer_blocks.0.norm1.bias
    - input_blocks.1.2.transformer_blocks.0.norm1.weight
    - input_blocks.1.2.transformer_blocks.0.norm2.bias
    - input_blocks.1.2.transformer_blocks.0.norm2.weight
    - input_blocks.1.2.transformer_blocks.0.norm3.bias
    - input_blocks.1.2.transformer_blocks.0.norm3.weight
    - input_blocks.1.2.transformer_blocks.0.pluker_projection.bias
    - input_blocks.1.2.transformer_blocks.0.pluker_projection.weight
    - input_blocks.2.0.emb_layers.1.bias
    - input_blocks.2.0.emb_layers.1.weight
    - input_blocks.2.0.in_layers.0.bias
    - input_blocks.2.0.in_layers.0.weight
    - input_blocks.2.0.in_layers.2.bias
    - input_blocks.2.0.in_layers.2.weight
    - input_blocks.2.0.out_layers.0.bias
    - input_blocks.2.0.out_layers.0.weight
    - input_blocks.2.0.out_layers.3.bias
    - input_blocks.2.0.out_layers.3.weight
    - input_blocks.2.0.temopral_conv.conv1.0.bias
    - input_blocks.2.0.temopral_conv.conv1.0.weight
    - input_blocks.2.0.temopral_conv.conv1.2.bias
    - input_blocks.2.0.temopral_conv.conv1.2.weight
    - input_blocks.2.0.temopral_conv.conv2.0.bias
    - input_blocks.2.0.temopral_conv.conv2.0.weight
    - input_blocks.2.0.temopral_conv.conv2.3.bias
    - input_blocks.2.0.temopral_conv.conv2.3.weight
    - input_blocks.2.0.temopral_conv.conv3.0.bias
    - input_blocks.2.0.temopral_conv.conv3.0.weight
    - input_blocks.2.0.temopral_conv.conv3.3.bias
    - input_blocks.2.0.temopral_conv.conv3.3.weight
    - input_blocks.2.0.temopral_conv.conv4.0.bias
    - input_blocks.2.0.temopral_conv.conv4.0.weight
    - input_blocks.2.0.temopral_conv.conv4.3.bias
    - input_blocks.2.0.temopral_conv.conv4.3.weight
    - input_blocks.2.1.norm.bias
    - input_blocks.2.1.norm.weight
    - input_blocks.2.1.proj_in.bias
    - input_blocks.2.1.proj_in.weight
    - input_blocks.2.1.proj_out.bias
    - input_blocks.2.1.proj_out.weight
    - input_blocks.2.1.transformer_blocks.0.attn1.to_k.weight
    - input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.bias
    - input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.weight
    - input_blocks.2.1.transformer_blocks.0.attn1.to_q.weight
    - input_blocks.2.1.transformer_blocks.0.attn1.to_v.weight
    - input_blocks.2.1.transformer_blocks.0.attn2.alpha
    - input_blocks.2.1.transformer_blocks.0.attn2.to_k.weight
    - input_blocks.2.1.transformer_blocks.0.attn2.to_k_ip.weight
    - input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.bias
    - input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.weight
    - input_blocks.2.1.transformer_blocks.0.attn2.to_q.weight
    - input_blocks.2.1.transformer_blocks.0.attn2.to_v.weight
    - input_blocks.2.1.transformer_blocks.0.attn2.to_v_ip.weight
    - input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.bias
    - input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.weight
    - input_blocks.2.1.transformer_blocks.0.ff.net.2.bias
    - input_blocks.2.1.transformer_blocks.0.ff.net.2.weight
    - input_blocks.2.1.transformer_blocks.0.norm1.bias
    - input_blocks.2.1.transformer_blocks.0.norm1.weight
    - input_blocks.2.1.transformer_blocks.0.norm2.bias
    - input_blocks.2.1.transformer_blocks.0.norm2.weight
    - input_blocks.2.1.transformer_blocks.0.norm3.bias
    - input_blocks.2.1.transformer_blocks.0.norm3.weight
    - input_blocks.2.2.norm.bias
    - input_blocks.2.2.norm.weight
    - input_blocks.2.2.proj_in.bias
    - input_blocks.2.2.proj_in.weight
    - input_blocks.2.2.proj_out.bias
    - input_blocks.2.2.proj_out.weight
    - input_blocks.2.2.transformer_blocks.0.attn1.to_k.weight
    - input_blocks.2.2.transformer_blocks.0.attn1.to_out.0.bias
    - input_blocks.2.2.transformer_blocks.0.attn1.to_out.0.weight
    - input_blocks.2.2.transformer_blocks.0.attn1.to_q.weight
    - input_blocks.2.2.transformer_blocks.0.attn1.to_v.weight
    - input_blocks.2.2.transformer_blocks.0.attn2.to_k.weight
    - input_blocks.2.2.transformer_blocks.0.attn2.to_out.0.bias
    - input_blocks.2.2.transformer_blocks.0.attn2.to_out.0.weight
    - input_blocks.2.2.transformer_blocks.0.attn2.to_q.weight
    - input_blocks.2.2.transformer_blocks.0.attn2.to_v.weight
    - input_blocks.2.2.transformer_blocks.0.epipolar.epipolar_attn.register_tokens
    - input_blocks.2.2.transformer_blocks.0.epipolar.epipolar_attn.to_k.weight
    - input_blocks.2.2.transformer_blocks.0.epipolar.epipolar_attn.to_out.0.bias
    - input_blocks.2.2.transformer_blocks.0.epipolar.epipolar_attn.to_out.0.weight
    - input_blocks.2.2.transformer_blocks.0.epipolar.epipolar_attn.to_q.weight
    - input_blocks.2.2.transformer_blocks.0.epipolar.epipolar_attn.to_v.weight
    - input_blocks.2.2.transformer_blocks.0.ff.net.0.proj.bias
    - input_blocks.2.2.transformer_blocks.0.ff.net.0.proj.weight
    - input_blocks.2.2.transformer_blocks.0.ff.net.2.bias
    - input_blocks.2.2.transformer_blocks.0.ff.net.2.weight
    - input_blocks.2.2.transformer_blocks.0.norm1.bias
    - input_blocks.2.2.transformer_blocks.0.norm1.weight
    - input_blocks.2.2.transformer_blocks.0.norm2.bias
    - input_blocks.2.2.transformer_blocks.0.norm2.weight
    - input_blocks.2.2.transformer_blocks.0.norm3.bias
    - input_blocks.2.2.transformer_blocks.0.norm3.weight
    - input_blocks.2.2.transformer_blocks.0.pluker_projection.bias
    - input_blocks.2.2.transformer_blocks.0.pluker_projection.weight
    - input_blocks.3.0.op.bias
    - input_blocks.3.0.op.weight
  zero_convolution: false
  cache3d_config:
    target: model.cache3d.cache3d_mvsplat.MvSplatCache3D
    params:
      height: 256
      width: 256
      keep_gaussians_on_device: true
      sequential: true
  linear_start: 0.00085
  linear_end: 0.012
  num_timesteps_cond: 1
  timesteps: 1000
  first_stage_key: video
  cond_stage_key: caption
  cond_stage_trainable: False
  conditioning_key: hybrid
  image_size: [32, 32]
  channels: 4
  scale_by_std: False
  scale_factor: 0.18215
  use_ema: False
  uncond_type: 'empty_seq'
  unet_config:
    target: lvdm.modules.networks.openaimodel3d.UNetModel
    params:
      in_channels: 8
      out_channels: 4
      model_channels: 320
      attention_resolutions:
      - 4
      - 2
      - 1
      num_res_blocks: 2
      channel_mult:
      - 1
      - 2
      - 4
      - 4
      dropout: 0.1
      num_head_channels: 64
      transformer_depth: 1
      context_dim: 1024
      use_linear: true
      use_checkpoint: True
      temporal_conv: True
      temporal_attention: True
      temporal_selfatt_only: true
      use_relative_position: false
      use_causal_attention: False
      temporal_length: 16
      addition_attention: true
      image_cross_attention: true
      image_cross_attention_scale_learnable: true
      default_fs: 3
      fs_condition: true

  first_stage_config:
    target: lvdm.models.autoencoder.AutoencoderKL
    params:
      embed_dim: 4
      monitor: val/rec_loss
      ddconfig:
        double_z: True
        z_channels: 4
        resolution: 256
        in_channels: 3
        out_ch: 3
        ch: 128
        ch_mult:
        - 1
        - 2
        - 4
        - 4
        num_res_blocks: 2
        attn_resolutions: []
        dropout: 0.0
      lossconfig:
        target: torch.nn.Identity

  cond_stage_config:
    target: lvdm.modules.encoders.condition.FrozenOpenCLIPEmbedder
    params:
      freeze: true
      layer: "penultimate"

  img_cond_stage_config:
    target: lvdm.modules.encoders.condition.FrozenOpenCLIPImageEmbedderV2
    params:
      freeze: true
  
  image_proj_stage_config:
    target: lvdm.modules.encoders.resampler.Resampler
    params:
      dim: 1024
      depth: 4
      dim_head: 64
      heads: 12
      num_queries: 16
      embedding_dim: 1280
      output_dim: 1024
      ff_mult: 4
      video_length: 16


